# 8. POS-tagging и NER  
## Формулировка задач, кодировки разметки, методы решения

---

## 1. Место POS и NER в обработке текста (NLP)

Обработка текста в машинном обучении обычно рассматривается как многоуровневый процесс:

- Символьный уровень — буквы, знаки
- Лексический уровень — токены (слова, подслова)
- **Морфологический уровень — POS-tagging**
- **Семантический уровень — NER**
- Синтаксический и дискурсивный уровни

POS-tagging и NER относятся к задачам **разметки последовательностей (sequence labeling)**, где каждому элементу входной последовательности сопоставляется метка, зависящая не только от самого элемента, но и от его контекста.

---

## 2. POS-tagging (Part-of-Speech tagging)

### 2.1 Формулировка задачи

**POS-tagging** — это задача автоматического определения части речи каждого токена в тексте с учётом контекста.

**Вход:**  
Последовательность токенов  
$$
x = (x_1, x_2, \dots, x_T)
$$

**Выход:**  
Последовательность тегов частей речи  
$$
y = (y_1, y_2, \dots, y_T), \quad y_t \in \mathcal{Y}
$$

где $\mathcal{Y}$ — конечный набор POS-тегов.

Тип задачи:
- многоклассовая классификация
- разметка последовательности (sequence labeling)

---

### 2.2 Почему POS — контекстная задача

Одна и та же форма слова может иметь разные части речи:

- *book* → существительное  
- *to book* → глагол  

Следовательно:
- классификация каждого слова независимо **некорректна**
- требуется учитывать соседние токены

---

### 2.3 Тегсеты (наборы POS-тегов)

Тегсет определяет алфавит классов задачи.

#### Penn Treebank (английский)
- ~45 тегов
- Примеры:
  - NN — существительное (ед.ч.)
  - NNS — существительное (мн.ч.)
  - VB — глагол (базовая форма)
  - JJ — прилагательное

#### Universal Dependencies (UD)
- ~17 универсальных категорий
- Кросс-язычный стандарт
- Примеры:
  - NOUN, VERB, ADJ, ADV, PROPN

#### OpenCorpora (русский)
- Детализированная морфология
- Учитывает род, число, падеж, время
- Используется в pymorphy2

**Важно:**  
Размер тегсета напрямую влияет на сложность задачи и выбор метрик.

---

## 3. Named Entity Recognition (NER)

### 3.1 Формулировка задачи

**NER** — задача автоматического выделения и классификации именованных сущностей в тексте.

Типичные классы:
- PERSON
- ORGANIZATION
- LOCATION
- DATE
- MONEY
- и др.

**Вход:**  
Последовательность токенов

**Выход:**  
Последовательность меток, указывающих:
- принадлежит ли токен сущности
- тип сущности
- границы сущности

NER также является задачей **sequence labeling**.

---

### 3.2 Почему нужна специальная кодировка

Именованные сущности могут состоять из нескольких токенов:

> *New York City*  
> *Procter & Gamble*

Следовательно, одного тега недостаточно — требуется кодировать **структуру сущности**.

---

## 4. Схемы кодировки сущностей (Tagging schemes)

### 4.1 IO-схема

- I — токен внутри сущности
- O — токен вне сущности

**Недостатки:**
- нет информации о границах
- невозможно корректно разделять соседние сущности

Используется редко.

---

### 4.2 BIO-схема (стандарт)

- **B-TYPE** — начало сущности
- **I-TYPE** — продолжение сущности
- **O** — вне сущности

Пример:

Текст:
```
Apple Inc. is based in Cupertino
```

Разметка:
```
Apple B-ORG  
Inc. I-ORG  
is O  
based O  
in O  
Cupertino B-LOC
```

**Преимущества BIO:**
- чёткие границы сущностей
- возможность ввести ограничения переходов
- устойчивость к ошибкам модели

---

### 4.3 BIOES / BMEO

Расширение BIO:

- B — Begin
- M / I — Middle / Inside
- E — End
- S — Singleton
- O — Outside

Используется, когда важна строгая структурная корректность.

---

## 5. POS и NER как задачи машинного обучения

### 5.1 Общая постановка

Модель обучается аппроксимировать:
$$
P(y_1, \dots, y_T \mid x_1, \dots, x_T)
$$

или локально:
$$
P(y_t \mid x_{1:T})
$$

---

## 6. Классические методы решения

### 6.1 Правила и словари
- ручные правила
- регулярные выражения
- списки сущностей

**Недостатки:** плохо масштабируются, не обобщаются.

---

### 6.2 Скрытые Марковские модели (HMM)

- моделируют:
  - переходы между тегами
  - вероятность слова при теге
- просты и интерпретируемы
- плохо работают с богатыми признаками

---

### 6.3 Условные случайные поля (CRF)

- discriminative-модель
- оптимизирует всю последовательность целиком
- учитывает допустимые переходы между тегами
- долгое время были state-of-the-art для POS и NER

---

## 7. Нейросетевые методы (основные)

### 7.1 CNN для POS-tagging (символьный уровень)

Идея:
- слово представляется как последовательность символов
- CNN извлекает морфологические признаки (суффиксы, окончания)

Типичная архитектура:
```

Символы → Embedding → Conv → ReLU → Pool → Flatten → Dense → Softmax
```

**Преимущества:**
- устойчивость к OOV словам
- хорошо работает для морфологически богатых языков

---

### 7.2 RNN / LSTM для POS и NER

Используется для учёта контекста:

```
Токены → Embedding → LSTM (return_sequences) → Dense → Softmax
```

- каждый выход соответствует одному токену
- скрытое состояние аккумулирует контекст
- особенно эффективно для NER

---

### 7.3 LSTM + CRF (классический гибрид)

- LSTM извлекает контекстные признаки
- CRF гарантирует структурную корректность BIO-разметки
- долгое время стандарт для NER

---

## 8. Современный стандарт: трансформеры

Модели:
- BERT
- RoBERTa
- XLM-R

Подход:
- контекстуальные эмбеддинги для каждого токена
- поверх — классификационный слой (иногда + CRF)
- fine-tuning на размеченных датасетах

**Преимущества:**
- глобальный контекст
- высокая точность
- переносимость между языками

---

## 9. Метрики качества

### Для POS:
- accuracy
- macro-F1 (важно при дисбалансе)

### Для NER:
- precision / recall / F1 по сущностям
- AUC-PR при сильном дисбалансе класса O

---

## 10. Итог

- POS и NER — ключевые задачи NLP
- обе формулируются как sequence labeling
- BIO/BIOES — обязательный элемент NER
- эволюция методов:
  - правила → HMM → CRF → LSTM → Transformers
- современные решения основаны на предобученных моделях и fine-tuning
